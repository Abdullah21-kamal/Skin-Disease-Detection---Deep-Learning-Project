{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport torch.nn as nn\nfrom glob import glob\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import ToTensor, Resize\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reading the Dataset**","metadata":{}},{"cell_type":"code","source":"import os\nimport random \nfrom glob import glob\nfrom pathlib import Path\n\nDATASET_DIR=\"../input/dermnet-and-skin-disease/Merged Dataset\"\nTEST_DIR=\"../input/dermnet-and-skin-disease/Merged Dataset/test\"\nTRAIN_DIR=\"../input/dermnet-and-skin-disease/Merged Dataset/Train\"\n\n\nall_data = [y for x in os.walk(DATASET_DIR) for y in glob(os.path.join(x[0], '*jpg'))]\nall_labels = [os.path.basename(os.path.dirname(x)) for x in all_data]\nprint(len(all_data))\nall_data[:10]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Classes with labels**","metadata":{}},{"cell_type":"code","source":"uniqe_labels=set(all_labels)\nprint(\"number of classes = \",len(uniqe_labels))\nprint(\"Here is the classes :\")\nfor label in uniqe_labels :\n  print (label)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Showing Image Samples from the dataset**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# Sample 25 images from dataset\nindices = np.random.randint(0, len(all_data), size=25)\nimages = [all_data[i] for i in indices]\nlabels = [all_labels[i] for i in indices]\n\n# Plot the 25 images\nplt.figure(figsize=(10,10))\nfor i in range(len(indices)):\n    plt.subplot(5, 5, i + 1)\n    image = mpimg.imread(images[i]) # Read image from disk\n    plt.imshow(image)\n    plt.title(labels[i])\n    plt.axis('off')\n    \nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Loading and preprocessing the data**\n**ResNet50 Model with final parameters**","metadata":{}},{"cell_type":"code","source":"## define train test and validation generators \nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\n\nBATCH_SIZE = 64\nHEIGHT = 224\nWIDTH = 224\n\n\n# 1. Construct an instance of the `ImageDataGenerator` class\ntrain_datagen =  ImageDataGenerator(\n      preprocessing_function = tf.keras.applications.resnet50.preprocess_input,\n      width_shift_range=0.4,\n      height_shift_range=0.3,\n      rotation_range=90,\n      validation_split=0.2,\n      zoom_range=0.2,\n    )\n\n# 2. Retrieve the iterator\ntrain_generator = train_datagen.flow_from_directory(TRAIN_DIR, \n                             shuffle = True,\n                            seed = 7,\n                            target_size=(HEIGHT, WIDTH), \n                            batch_size=BATCH_SIZE,\n                            color_mode='rgb',\n                            class_mode='categorical',\n                            subset='training'\n                                                   )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_generator = train_datagen.flow_from_directory(\n                             TRAIN_DIR, \n                             shuffle = True,\n                            seed = 7,\n                            target_size=(HEIGHT, WIDTH), \n                            batch_size=BATCH_SIZE,\n                            color_mode='rgb',\n                            class_mode='categorical',\n                            subset='validation'\n    )\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_datagen =  ImageDataGenerator(\n    preprocessing_function = tf.keras.applications.resnet50.preprocess_input\n    )\n\n# 2. Retrieve the iterator\ntest_generator = test_datagen.flow_from_directory(TEST_DIR, \n                                                    target_size=(HEIGHT, WIDTH), \n                                                    batch_size=BATCH_SIZE,\n                                                   color_mode='rgb',\n                                                    shuffle=False,\n                                                    class_mode='categorical',\n                                                  )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.resnet50 import ResNet50\nfrom keras.models import Model\nfrom keras.layers import Dense, Flatten, Dropout\n\n# Load model without classification head\nbase_model = ResNet50(include_top = False,\n                   weights = 'imagenet',\n                   input_shape = (HEIGHT, WIDTH, 3))\n\n# Print base model summary\nbase_model.summary()\n\n# Mark loaded layers as trainable\nfor layer in base_model.layers[25:45]:\n  layer.trainable = True\n\n# Adding new classifier layers\nx = Flatten()(base_model.layers[-1].output)\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(256, activation='relu')(x)\noutput = Dense(23, activation='softmax')(x)\n\n# Define new model\nmodel_Res50 = Model(inputs = base_model.inputs, outputs = output)\n\n# Print summary\nmodel_Res50.summary()\n\n# Compile\nbase_learning_rate = 0.0001\nmodel_Res50.compile(optimizer = tf.keras.optimizers.Adam(lr = base_learning_rate),\n            loss = 'categorical_crossentropy',\n            metrics = ['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nINITIAL_EPOCHS = 10\n\nhistory = model_Res50.fit(train_generator,\n                    validation_data = val_generator,\n                    epochs = INITIAL_EPOCHS)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plotting Graphs for ResNet model**","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##EValuting the model\nmodel_Res50.evaluate(test_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicions=model_Res50.predict(test_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Confusion Matrix**","metadata":{}},{"cell_type":"code","source":"import numpy as np\npredicted_classes=np.argmax(predicions,axis=1)  \ntrue_classes=test_generator.classes  \ntest_labels=list(test_generator.class_indices.keys())\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\n\n\ncm = confusion_matrix(true_classes,predicted_classes)\n\ncm_disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=test_labels)\n\ncm_disp = ConfusionMatrixDisplay(confusion_matrix=cm)\nfig, ax = plt.subplots(figsize=(10,10))\ncm_disp.plot(ax=ax)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nreport=classification_report(true_classes, predicted_classes)\nprint(report)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**VGG Model with final hyperparameters**","metadata":{}},{"cell_type":"code","source":"## define train test and validation generators \nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\n\nBATCH_SIZE = 64\nHEIGHT = 224\nWIDTH = 224\n\n\n# 1. Construct an instance of the `ImageDataGenerator` class\ntrain_datagen =  ImageDataGenerator(\n      preprocessing_function = tf.keras.applications.vgg16.preprocess_input,\n      width_shift_range=0.4,\n      height_shift_range=0.3,\n      rotation_range=90,\n      validation_split=0.2,\n      zoom_range=0.2,\n    )\n\n# 2. Retrieve the iterator\ntrain_generator = train_datagen.flow_from_directory(TRAIN_DIR, \n                             shuffle = True,\n                            seed = 7,\n                            target_size=(HEIGHT, WIDTH), \n                            batch_size=BATCH_SIZE,\n                            color_mode='rgb',\n                            class_mode='categorical',\n                            subset='training'\n                                                   )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_generator = train_datagen.flow_from_directory(\n                             TRAIN_DIR, \n                             shuffle = True,\n                            seed = 7,\n                            target_size=(HEIGHT, WIDTH), \n                            batch_size=BATCH_SIZE,\n                            color_mode='rgb',\n                            class_mode='categorical',\n                            subset='validation'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_datagen =  ImageDataGenerator(\n    preprocessing_function = tf.keras.applications.vgg16.preprocess_input\n    )\n\n# 2. Retrieve the iterator\ntest_generator = test_datagen.flow_from_directory(TEST_DIR, \n                                                    target_size=(HEIGHT, WIDTH), \n                                                    batch_size=BATCH_SIZE,\n                                                   color_mode='rgb',\n                                                    shuffle=False,\n                                                    class_mode='categorical',\n                                                  )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.layers import Dense, Flatten, Dropout\n\n# Load model without classification head\nbase_model = VGG16(include_top = False,\n                   weights = 'imagenet',\n                   input_shape = (HEIGHT, WIDTH, 3))\n\n# Print base model summary\nbase_model.summary()\n\n# Mark loaded layers as not trainable\n\n# You can choose to fine-tune some of the final layers:\nfor layer in base_model.layers[8:14]:\n    layer.trainable = True\n\n# You can pick which layers are trainable and which are not:\n #base_model.get_layer('block1_conv1').trainable = False\n\n\n# Add new classifier layers\nx = Flatten()(base_model.layers[-1].output)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(256, activation='relu')(x)\noutput = Dense(23, activation='softmax')(x)\n\n# Define new model\nmodel = Model(inputs = base_model.inputs, outputs = output)\n\n# Print summary\nmodel.summary()\n\n# Compile\nbase_learning_rate = 0.0001\nmodel.compile(optimizer = tf.keras.optimizers.RMSprop(lr = base_learning_rate),\n            loss = 'binary_crossentropy',\n            metrics = ['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicions=model.predict(test_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_classes=np.argmax(predicions,axis=1)  \ntrue_classes=test_generator.classes  \ntest_labels=list(test_generator.class_indices.keys())\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\n\ncm = confusion_matrix(true_classes,predicted_classes)\n\ncm_disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=test_labels)\n\ncm_disp = ConfusionMatrixDisplay(confusion_matrix=cm)\nfig, ax = plt.subplots(figsize=(15,15))\ncm_disp.plot(ax=ax)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nreport=classification_report(true_classes, predicted_classes)\nprint(report)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Xception Model with final Parameters**","metadata":{}},{"cell_type":"code","source":"## define train test and validation generators modelmodel_Res50\nBATCH_SIZE = 64\nHEIGHT = 224\nWIDTH = 224\n\n\n# 1. Construct an instance of the `ImageDataGenerator` class\ntrain_datagen =  ImageDataGenerator(\n      preprocessing_function = tf.keras.applications.xception.preprocess_input,\n      width_shift_range=0.4,\n      height_shift_range=0.3,\n      rotation_range=90,\n      validation_split=0.2,\n      zoom_range=0.2,\n     \n    )\n\n# 2. Retrieve the iterator\ntrain_generator = train_datagen.flow_from_directory(TRAIN_DIR, \n                             shuffle = True,\n                            seed = 7,\n                            target_size=(HEIGHT, WIDTH), \n                            batch_size=BATCH_SIZE,\n                            color_mode='rgb',\n                            class_mode='categorical',\n                            subset='training'\n                                                   )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_generator = train_datagen.flow_from_directory(\n                             TRAIN_DIR, \n                             shuffle = True,\n                            seed = 7,\n                            target_size=(HEIGHT, WIDTH), \n                            batch_size=BATCH_SIZE,\n                            color_mode='rgb',\n                            class_mode='categorical',\n                            subset='validation'\n    )\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_datagen =  ImageDataGenerator(\n    preprocessing_function = tf.keras.applications.xception.preprocess_input\n    )\n\n# 2. Retrieve the iterator\ntest_generator = test_datagen.flow_from_directory(TEST_DIR, \n                                                    target_size=(HEIGHT, WIDTH), \n                                                    batch_size=BATCH_SIZE,\n                                                   color_mode='rgb',\n                                                    shuffle=False,\n                                                    class_mode='categorical',\n                                                  )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.xception import Xception\nfrom keras.models import Model\nfrom keras.layers import Dense, Flatten, Dropout\n\n\n\n\n# Load model without classification head\nbase_model = Xception(include_top = False,\n                   weights = 'imagenet',\n                   input_shape = (HEIGHT, WIDTH, 3))\n\n# Print base model summary\nbase_model.summary()\n\n# Mark loaded layers as not trainable\nfor layer in base_model.layers[30:60]:\n  layer.trainable = True\n\n       \n# Adding new classifier layers\nx = Flatten()(base_model.layers[-1].output)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.7)(x)\nx = Dense(256, activation='relu')(x)\noutput = Dense(23, activation='softmax')(x)\n\n# Define new model\nmodel_Xception = Model(inputs = base_model.inputs, outputs = output)\n\n# Print summary\nmodel_Xception.summary()\n\n# Compile\nbase_learning_rate = 0.0001\nmodel_Xception.compile(optimizer = tf.keras.optimizers.Adam(lr = base_learning_rate),\n            loss = 'categorical_crossentropy',\n            metrics = ['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INITIAL_EPOCHS =10\n\nhistory = model_Xception.fit(train_generator,\n                    validation_data = val_generator,\n                    epochs = INITIAL_EPOCHS)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicions=model_Xception.predict(test_generator)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\npredicted_classes=np.argmax(predicions,axis=1)  \ntrue_classes=test_generator.classes  \ntest_labels=list(test_generator.class_indices.keys())\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\ncm = confusion_matrix(true_classes,predicted_classes)\ncm_disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=test_labels)\ncm_disp = ConfusionMatrixDisplay(confusion_matrix=cm)\nfig, ax = plt.subplots(figsize=(10,10))\ncm_disp.plot(ax=ax)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nreport=classification_report(true_classes, predicted_classes)\nprint(report)","metadata":{},"execution_count":null,"outputs":[]}]}